{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7fc6d8-2b5a-4b54-9d04-d6aad474045e",
   "metadata": {},
   "source": [
    "# Enviar job de Vertex\n",
    "Enviar job de vertex para el entrenamiento del modelo en cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6689c3c4-217a-4704-9795-d7ab10baffa0",
   "metadata": {},
   "source": [
    "## Consideraciones generales importantes Vertex AI - Noviembre 2023\n",
    "- El job de entrenamiento que se envia se guarda en el menu principal **\"Model Development\"**, específicamente en el submenú **\"Entrenamiento\"**\n",
    "\n",
    "- Por otro lado, el modelo que queda entrenado queda registrado en el menu principal **\"Deploy and Use\"**, específicmente en el submenú **\"Registro de Modelos\"** (solo si se logro ejecutar bien el job y entrenó el modelo. Este funciona como un repositorio de modedlos). Luego de tener registrado el modelo, si se desea, se puede deployar en un endpoint (para realizar predicciones en línea con un delay muy pequeño)  y el endpoint queda registrado en el menu **\"EndPoint\"**\n",
    "\n",
    "## Consideraciones para el entrenamiento realizado en este notebook\n",
    "- Se utiliza la clase **CustomTrainingJob**. Documentación: https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#methods\n",
    "- **En este ejemplo, se ENVIA UN SCRIPT CON EL CÓDIGO DE ENTRENAMIENTO A GCP.**\n",
    "\n",
    "\n",
    "- **DOCUMENTACIÓN PYTHON DE LA LIBRERÍA COMPLETA AIPLATFORM**, INCLUYE ENTRE OTROS EL **CustomTrainingJob** QUE SE UTILIZA PARA ENVIAR UN SCRIPT DE ENTRENAMIENTO A LA NUBE, el que se utiliza más adelante en este ejemplo https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform\n",
    "\n",
    "- **Repo Github oficial de Vertex AI - ejemplos interesantes**:\n",
    "- https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_with_vertex_distributed_training.ipynb\n",
    "- https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/hyperparameter_tuning_xgboost.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35579d27-5406-4fcd-8a5c-4749dfc82e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2c46c-1478-4617-84ef-dec1a5e5b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7db2e-2608-4153-abba-6bd9b3568688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223bb49-efdf-423a-bca3-9eb6cbc07fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58919ac-7e0d-4b5c-a112-a8672feb8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # package used in jupyter notebook to read the variables in file .env\n",
    "\n",
    "\"\"\" get env variable from .env \"\"\"\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\"\"\" Read env variables and save it as python variable \"\"\"\n",
    "PROJECT_ID_DS = os.environ.get(\"PROJECT_GCP\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5987f6-087a-4fc9-b53f-9b9cf94cdc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d64f6936-d0f3-47ac-9936-564a722d1149",
   "metadata": {},
   "source": [
    "### Paso 0. Parámetros generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7da85-9f5b-418f-9ed4-ff0ff6a9a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARÁMETROS GENERALES GCP ###\n",
    "\n",
    "# definir el proyecto. Diría que se tiene que hacer todo en un único proyecto porque sino vertex como que no funciona (creo)\n",
    "PROJECT_ID = PROJECT_ID_DS\n",
    "\n",
    "# definir un bucket (ya creado) para guardar los archivos que genera el usar VERTEX AI.\n",
    "# No necesariamente puede ser un bucket, puede ser una carpeta dentro de un bucket. Lo cual es mejor si se quiere tener un\n",
    "# bucket para un caso de uso y dentro de ese bucket un folder dedicado a todo los códigos de VERTEX AI\n",
    "BUCKET_ID = '{bucket_name}/vertex-ai'\n",
    "\n",
    "# definir una región, VERTEX SE INICIALIZA EN UNA REGIÓN y se utiliza algún recursos de vertex ej: datesets deben de estar \n",
    "# definidos en la misma región que se inicializó el código. Importante mayo 2023: dataset no están implementados para todas las regiones\n",
    "REGION = '{region}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838c8f4-ba9a-45a4-9b00-6957ef03d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARÁMETROS GENERALES EJECUCIÓN ###\n",
    "\n",
    "# obtener la hora actual de cuándo se comenzó la ejecución - hash\n",
    "now = dt.datetime.now()\n",
    "date_time = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "# identificacion del tipo de caso de uso (y también tipo de modelo) que se va a usar poara registrar el entrenamiento\n",
    "identity_kind_use_case = 'basic_job_vertex'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5639c-99e3-4910-bfc8-333527855493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parámetros Generales GCP')\n",
    "print('PROJECT_ID: ', PROJECT_ID)\n",
    "print('BUCKET_ID: ', BUCKET_ID)\n",
    "print('REGION: ', REGION)\n",
    "\n",
    "print('\\n----')\n",
    "print('Parámetros Específicos job entrenamiento')\n",
    "print('date_time: ', date_time)\n",
    "print('identity_kind_use_case: ', identity_kind_use_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44becc64-5a64-43ac-8611-1918ee12616b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb9540f-8a52-4881-9b35-82c580affff6",
   "metadata": {},
   "source": [
    "### Paso 1. Crear script de entrenamiento\n",
    "\n",
    "### Información importante\n",
    "- Enviar un job de entrenamiento utilizando la función **\"CustomTrainingJob\"** que **envia un script de python para ser corrido en la nube**. No acepta carpetas con multiples scripts.\n",
    "\n",
    "\n",
    "- El script de entrenamiento puede tener también escrita la limpieza/transformación de los datos, no hay problema en eso (se le pueden pasar los datos ya limpios llegar y entrenar o se le puedan pasar los datos sucios y que los limpie primero y luego entrene el modelo). El script de entrenamiento soporta todo el código que se desee agregar (solo la consideración mencionada al inicio, tiene que ser SOLO UN SCRIPT)\n",
    "\n",
    "\n",
    "- **El script que se le pasa al job de entrenamiento puede recibir argumentos.** Los valores de los argumentos del script se le pasan a vertex AI cuando se envía el job para correr el script y entrenar el modelo.\n",
    "\n",
    "\n",
    "- Los argumentos que se le pasan al script del job de entrenamiento puede ser la típica variable (ej: batch_size = 14), así como también strings los cuales pueden ser el path a algún archivo de GCS por ejemplo (Ej: pasar como argumento el path de un json de GCS, donde este json tiene múltiples parámetros para ser usados en el script.py). **ENTONCES, si se le quieren pasar múltiples argumentos y tiene que definirse 1 por 1 haciendo un listado gigante de argumentos, se le puede pasar un solo argumento con el path a un json de gcs, el cual contiene todos los argumentos de entrenamiento** (luego ese json con todos los parámetros puede ser modificado de acuerdo a lo que se necesite y el código para entrenar el modelo permanece sin cambios).\n",
    "\n",
    "\n",
    "- El script.py que se crea no necesita un método __init__, basta con escribir el código y listo.\n",
    "\n",
    "\n",
    "- El script de entrenamiento para cloud, NO TIENE NINGUNA DIFERENCIA CON UN SCRIPT DE ENTRENAMIENTO QUE SE CORRA LOCAL. Es decir, **si tengo un script de entrenamiento que corro localmente, puedo ese mismo script enviarlo a VERTEX AI sin modificarlo nada y listo, modelo entrenado en cloud**\n",
    "\n",
    "\n",
    "- **MUY IMPORTANTE** CUANDO SE CORRE EL SCRIPT DE ENTRENAMIENTO, ENTRENA EL MODELO, PERO NO LO REGISTRA EN EL MENU \"MODELOS\" DE FORMA AUTOMÁTICA. PARA QUE EL **MODELO QUEDE REGISTRADO EN EL MENU \"MODELOS\" (y después usarse para predecir batch o implementarlo para predecir en línea) SE NECESITA GUARDAR EL MODELO EN GCS**, PERO ADEMÁS, SE NECESITA GUARDAR EN UN PATH EN ESPECÍFICO DEFINIDO COMO UNA VARIABLE GLOBAL **\"AIP_MODEL_DIR\"**. Además el **artefacto con el modelo debe quedar guardado en GCS con el nombre \"model.pkl\" SÍ O SÍ**. Pero, el problema es que si no se desea registrar el modelo, se omite la parte de guardar, el código corre con normalidad pero POR DEFECTO VERTEX VA A BUSCAR EL MODELO PARA REGISTRARLO Y ESTE AL NO EXISTIR (no haberse guardado) TIRA ERROR EN EL ENTRENAMIENTO, lo que dificulta un poco más el proceso de debugging cuando falla algo\n",
    "\n",
    "\n",
    "- Ejemplo del path por defecto **AIP_MODEL_DIR**: gs://{bucket-name}/aiplatform-custom-training-2022-05-01-13:27:34.025/model/. Donde \"dicovery-vertex-ai\" es el bucket definido al inicializar la libreria ai platform de vertex. El resto se crea de forma automática. Cuando se guarda el artefacto del modelo, el path queda de la siguiente forma: **gs://{bucket-name}/aiplatform-custom-training-2022-05-01-13:27:34.025/model/model.pkl**\n",
    "\n",
    "\n",
    "- Importante, por defecto **VERTEX SIEMPRE NECESITA QUE EL PATH AL ARTEFACTO DEL MODELO SEA DE LA FORMA \".../model/model.pkl\"** Esto quiere decir que siempre debe existir una carpeta model y dentro de esta un artefacto model.pkl. Además, lo ideal es que existe una carpeta para identificar el caso de uso y un hash para identificar la ejecución. Así el **path de guardado queda de la forma \"gs://{bucket}/{use_case + hash}/model/model.pkl\"** Un path de este estilo es creado por defecto en las ejecuciones de los jobs si no se toca la variable de ambiente **\"AIP_MODEL_DIR\"** en el script de entrenamiento y el argumento **base_output_dir** al momento de enviar el job\n",
    "\n",
    "\n",
    "- De acuerdo a los valores de los parámetros (leer documentación), es posible modificar el path donde se va a guardar el modelo y que no sea el que se crea automáticamente que queda guardado en **\"AIP_MODEL_DIR\"**, sino en un path de GCS definido por el usuario. Lo importante es definir el argumento **base_output_dir** con el path donde vertex va a buscar el modelo para registrarlo, y luego al guardar el artefacto en GCS utilizar ese mismo path; y no el automático. **MUY IMPORTANTE el path que se define en base_output_dir debe ser de la forma \"gs://{bucket}/{use_case + hash}/\"**, es decir debe omitirse del path \".../model/model.pkl\" ya que es lo obligatorio de vertex. Obviamente al guardar el artefacto del modelo debe hacerse en la ruta completa \"gs://{bucket}/{use_case + hash}/model/model.pkl\"\n",
    "\n",
    "\n",
    "- **Documentación variable ambiente** (ej AIP_MODEL_DIR donde se guarda el artefacto del modelo): https://cloud.google.com/vertex-ai/docs/training/code-requirements#environment-variables\n",
    "- **Documentación guardar modelos vertex ai (entrenando en vertex ai)(guardar el pkl resultante en un cierto path, para que customtrainingjob lo reconozca)**: https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts?hl=es-419#scikit-learn\n",
    "- **Documentación clase CustomTrainingJob**: https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob#methods\n",
    "- **Repo Github oficial de Vertex AI - ejemplo interesante**: https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_with_vertex_distributed_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f63ea-978d-484d-8a7a-31732ac82d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBIR EL SCRIPT DE ENTRENAMIENTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf0496-6cb8-4233-b372-48620066487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBAR CORRER EL SCRIPT QUE GENERÉ, PARA VER SI FUNCIONA (lo ideal es probar con un dataset pequeño)\n",
    "# %run train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94583e6f-8e88-40bd-8aec-3ffc312df6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e08ad561-ba02-42c3-beed-386938c85221",
   "metadata": {},
   "source": [
    "### Paso 2: Inicializar Vertex AI\n",
    "- Antes de poder enviar un job de entrenamiento o realizar cualquier operación en VERTEX AI es necesario inicializarlo.\n",
    "\n",
    "\n",
    "- Parámetros necesarios para inicializar:\n",
    "    - project: El projecto de GCP\n",
    "    - location: La región en la que se va a ejecutar el entrenamiento\n",
    "    - staging_bucket: el bucket de GCS donde se guardan los artefactos que generan los jobs de entrenamiento de vertex\n",
    "\n",
    "\n",
    "- Documentación: https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_init\n",
    "\n",
    "\n",
    "- Total de parámetros que se le puede pasar al método init (ver documentación): project, location, experiment (no sé que es), experiment_description, staging_bucket, credentials, ncryption_spec_key_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d022d87-5159-420e-bfb3-da14f417cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = REGION, staging_bucket = BUCKET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44aa64b-0fa5-4f1e-90fe-793432e2d5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f91ab47-0ab9-4aec-85b3-5745690a5ca1",
   "metadata": {},
   "source": [
    "### Paso 3. Definir parámetros necesarios para CREAR la instancia del job de entrenamiento (aún no se envia)\n",
    "\n",
    "- Para entrenar un modelo en cloud se deben realizar 2 pasos: el primero crear la instancia de la clase del entrenamiento (CustomTrainingJob) y en segundo lugar enviar el job de entrenamiento (método de la instancia)\n",
    "\n",
    "---------------------------\n",
    "- Para crear la instancia de la clase del job de entrenamiento, se necesitan los siguientes parámetros:\n",
    "    - **display_name**: El nombre del job de entrenamiento. Con este nombre queda registrado el job de entrenamiento\n",
    "    - **script_path**: El nombre del script.py que se envia para entrenamiento\n",
    "    - **container_uri**: El path con la imagen docker para el entrenamiento. Puede ser de las facilitadas por google o una propia. Recomendable utilizar una de google y solo instalar los packages faltantes en esa instancia. Crear una propia desde cero es un problema.\n",
    "    - **model_description**: Descripción que aparece en el menú \"modelos\" del modelo que se registre\n",
    "    - **requirements**: Requisitos de packages a instalar en la imagen pasada en container_uri\n",
    "    - **model_serving_container_image_uri**: Path con la imagen docker para las prediciones. Facilitad por google o una propia\n",
    "\n",
    "\n",
    "---------------------------\n",
    "- INFO containers base de google:\n",
    "    - **Container para el entrenamiento**: https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "    - **Container para la predicción**: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "\n",
    "---------------------------\n",
    "- INFO, LOS ÚNICOS PARÁMETROS QUE SON OBLIGATORIOS SON:\n",
    "    - **display_name**\n",
    "    - **script_path**\n",
    "    - **container_uri**\n",
    "\n",
    "---------------------------\n",
    "- Documetación de la clase **\"CustomTrainingJob\"** (se usa para crear la instancia y luego correr el método run para enviar a su entrenamiento): https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob\n",
    "\n",
    "\n",
    "- **IMPORTANTÍSIMO mayo 2023: Los contenedores prebuild de \"sklearn\" están muy desactualizados. Por lo tanto lo ideal es utilizar los container de \"tensorflow\" ya que estos containers prebuild que GCP actualiza y agregar en los requirements los package que faltan. El container prebuild de tensorflow tiene las mismas versiones que los notebooks de workbench que tiene Vertex así entrenar un modelo en el workbench es compatible con enviar el job de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da08a45-5221-4882-8d9a-d4543851336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir el nombre del job que se enviará. Algo que indentifique de qué es el job + hora envio ###\n",
    "job_name = identity_kind_use_case + '__job_train__' + date_time\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e75bd-fb8b-408d-a619-b4e0f58ac0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### definir el contrainer para el ENTRENAMIENTO y para LA PREDICCIÓN - facilitados por google ####\n",
    "# container_train = 'us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest'\n",
    "# container_deploy = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-23:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278e921-dc51-45e2-8df7-af47d9ff2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir container para el ENTRENAMIENTO y predicción online - UTILIZAR LOS ÚLTIMOS DE TF e instalar packages faltantes. NOV 2023\n",
    "container_train = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest'\n",
    "container_deploy = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e8d99-8603-479e-88fa-e35af0ee30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir el path al script de entrenamiento ###\n",
    "path_train_script = 'train_model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05025e-b6cd-49b1-b5b8-dd36f5ff04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir la descripción del modelo ###\n",
    "description = 'entrenar modelo basico vertex AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551ec93-e15d-42c3-94fa-8f30cf2f47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir los requirements ###\n",
    "\n",
    "# el db-types es necesario para poder consultar tablas de bigquery\n",
    "list_requirements = [\"google-cloud-bigquery>=2.20.0\", \"db-dtypes\", \"pandas==2.0.3\", \"numpy==1.23.5\", \"scikit-learn==1.3.1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c140376-6c0d-462c-a315-a8fdd4b1871a",
   "metadata": {},
   "source": [
    "### Paso 4. Definir parámetros necesarios para ENVIAR job de entrenamiento - usando CPU\n",
    "\n",
    "- The run function creates a training pipeline that trains and creates a Model object. After the training pipeline completes, the run function returns the Model object.\n",
    "\n",
    "\n",
    "- La istancia de la clase \"CustomTrainingJob\" definida como \"job\" se le llama el método **\"run\" \"job.run(xxx)\"** y se envía el job de entrenamiento a VERTEX AI. **Al llamar al método \"run\" se puede hacer SIN PASARLE NADA o PASÁNDOLE ARGUMENTOS (opcionales)**\n",
    "\n",
    "\n",
    "- Algunos de los ARGUMENTOS que se le pueden pasar al método **\"run\"** son los siguientes:\n",
    "\n",
    "    - model_display_name: The display name of the Model if the script produces a managed Model (Si no se le da un nombre al modelo, se emplea el mismo nombre que se le dio al job y se le agrega el sufijo \"-model\")\n",
    "    - machine_type: The type of machine to use for training. Por defecto utiliza: \"n1-standard-4\"\n",
    "    - **args**: The command line arguments to be passed to the Python script. Se pasa una lista con los args. Ejemplo 1: [\"--epochs=5\", \"--batch_size=16\", \"--distribute=multiworker\"]. Ejemplo 2: [\"--model-dir=\" + MODEL_DIR, \"--epochs=5\"]\n",
    "    - replica_count: The number of worker replicas.\n",
    "    - accelerator_type: The hardware accelerator type. (Parámetro GPU: qué gpu utilizar par entrenamiento)\n",
    "    - accelerator_count: The number of accelerators to attach to a worker replica. (Parámetro GPU: cantidad de gpu a utilizar)\n",
    "    - **base_output_dir**: **GCS output directory of job**. Path de GCS donde se dice que está guardado el modelo y que se utiliza para registrarlo en el submenú \"models\", **si no se le pone nada utiliza el valor por defecto que es la variable de entorno 'AIP_MODEL_DIR'**\n",
    "\n",
    "\n",
    "- **Ningún argumento es obligatorio (todos tienen sus valores por defecto). Se completan de acuerdo a la necesidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e445f2c-7247-4274-8ec8-5d601dddf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir el nombre con el que queda registrado (en VERTEX AI) el modelo resultado del entrenamiento ###\n",
    "# De qué es el modelo +  hora de envio\n",
    "model_name = identity_kind_use_case  + '__model__' + date_time \n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf300ff9-d2c0-441b-8bd4-6af36cd75793",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir el tipo de máquina para hacer el entrenamiento ###\n",
    "\n",
    "machine_type_train = \"n1-standard\"\n",
    "vcpu_train = \"4\"\n",
    "train_compute = machine_type_train + \"-\" + vcpu_train\n",
    "\n",
    "print(\"Train machine type: \", train_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7944053-0e9b-46c9-b26f-d2613b3ea147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13db567a-76d7-4d08-8ed7-5a79b05ed440",
   "metadata": {},
   "source": [
    "### Paso 5. Crear instancia del job de entrenamiento a VERTEX AI (CustomTrainingJob)\n",
    "- Define your custom TrainingPipeline on Vertex AI.\n",
    "\n",
    "\n",
    "- Use the **CustomTrainingJob class** to define the TrainingPipeline.\n",
    "\n",
    "\n",
    "- **IMPORTANTE, AÚN NO SE ENTRENADA NADA NI SE CREA NADA EN VERTEX**: \n",
    "\n",
    "    - Cuando se crea la instancia \"job\" de la clase \"CustomTrainingJob\" aún no aparece nada registrado en el menú \"Entrenamiento\" de VERTEX AI\n",
    "    \n",
    "    - De la instancia creada, definida por la variable \"job\", **aún no se le pueda llamar ningún atributo por ejemplo **\"job.resource_name\" porque aún no se crea nada en VERTEX AI**. Por lo tanto si llamara \"job.resource_name\" u otro atributo retornaría el siguiente error \"CustomTrainingJob resource has not been created\"; para poder llamar estos atributos es necesario enviar el job creado a ser entrenado \"job.run()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c16ba-3283-442d-a5b3-c794ba7ac80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMERO SE LLAMA UNA INSTANCIA DE LA CLASE\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name = job_name,\n",
    "    script_path = path_train_script,\n",
    "    model_description = description,\n",
    "    container_uri = container_train,\n",
    "    requirements = list_requirements,\n",
    "    model_serving_container_image_uri = container_deploy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241d459-6a96-44eb-a4a6-7b64ea385a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f120d-ede4-49f6-bcd6-104da3f56470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d824845-1ab9-4b05-a6cc-51a832ca1940",
   "metadata": {},
   "source": [
    "### Paso 6. Enviar el job de entrenamiento a VERTEX AI (CustomTrainingJob)\n",
    "\n",
    "- Use the run function to start training\n",
    "\n",
    "- Luego de ser enviado el job de entrenamiento y este terminado correctamente aparecen **3 registros en vertex AI**. El primero en el **menú \"models\"** donde está el modelo entrenado y otros dos en **menu entrenamiento**, uno en el sub menú **\"entrenamiento/trainning pipelines\"** y otro en el sub menu **\"entrenamiento/custom jobs\"**\n",
    "\n",
    "\n",
    "- Importante, **al script de entrenamiento se le puede poner PRINTS, los cuales al abrir el job de entrenamiento en vertex (menu entrenamiento/custom jobs), aparece la opción de ir al logging/registros**, y de ahí ver los loggins del job enviado (el cual incluye los print)\n",
    "\n",
    "\n",
    "- Importante 2: Al **enviar el job de entrenamiento a VERTEX AI se guardan dos archivos en el bucket de GCS definido al inicializar Vertex AI**\n",
    "    - Un archivo **comprimido .tar.gz** donde se guarda el script que se envió al entrenamiento. Para identificar el archivo se le añade la fecha de forma automática en que este se corrió (creo que no se puede modificar el nombre desde parámetros). Se guarda por defecto en el bucket definido al inicializar vertex.\n",
    "    - Una **carpeta donde se guarda el artefacto del modelo**. Para identificar la carpeta se añade la fecha de forma automática en que esta es creada. El path a esta carpeta se guarda en la variable de ambiente \"AIP_MODEL_DIR\" (este path si se puede modificar)\n",
    "    - OBS: tanto el archivo compromido como la carpeta tiene una fecha, PERO ESTA ES DISTINTA EN CADA UNO DE LOS ARCHIVOS, porque estos artefactos NO se crean al mismo tiempo\n",
    "    \n",
    "    \n",
    "- Importante 2.b. La ubicación del compromido con los paquetes y la carpeta con el modelo se pueden ver en el menu \"entrenamiento\" seleccionado el job que se desea revisar y posteriormente clickeando en \"detalles de la versión\"\n",
    "  \n",
    "\n",
    "- Importante 3. En el menu \"modelos\" uno puede elegir el modelo y lo envia a un menu con las diferentes versiones de ese modelo, y al hacer click en el ID de la versión, me envía a un menú más detallado del modelo (si quiero implementarlo, hacer predicciones batch, detalles de la versión). El cual es el mismo menú que aparece si uno va a \"entrenamiento/training pipelines\" elige el job de entrenamiento y reenvia al menú más detallado del modelo. Es decir, **se puede acceder al menu detallado del modelo ya sea desde el menu \"models\" y buscando el modelo y su versión específica o desde el menu \"entrenamiento\" y seleccionando el pipeline job que generó dicho modelo**\n",
    "\n",
    "- Importante 4. Para que **no aparesca el texto que está corriendo el job y se pueda seguir utilizando el código se puede utilizar el parámetro \"sync\" y setear en \"False\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204773c0-9572-48ad-b1b4-e49ad3ef21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    model_display_name = model_name,\n",
    "    replica_count = 1,\n",
    "    machine_type = train_compute,\n",
    "    sync = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a6f82-c832-4e65-9bc5-fb34dad61d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275eca-f84a-4735-8e5d-40898d845947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b017067-497b-4dda-8068-d53fa5943f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30ff2d-c8f1-4b7b-babe-d2386a1139ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
